{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('always', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "# Pipeline imports\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectPercentile, chi2, SelectKBest\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler,FunctionTransformer\n",
    "from sklearn import tree\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "\n",
    "def BMI(weight, height):\n",
    "    return weight/(height**2/(100*100))\n",
    "\n",
    "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, threshold_BMI=30, threshold_Polydipsia= 2.5):\n",
    "        X = self._BMI(X, threshold=threshold_BMI)\n",
    "        X = self._fix_polydipsia(X, threshold=threshold_Polydipsia)\n",
    "        return X\n",
    "    \n",
    "    def _BMI(self, X, y=None, threshold=30):\n",
    "        # Perform arbitary transformation\n",
    "\n",
    "\n",
    "        idx = X[X['Obesity'].isna()].index\n",
    "        \n",
    "        # indexes to identify BMI above or below threshold\n",
    "        idx2 = X.loc[idx,].loc[BMI(X.loc[idx,][\"Weight\"], X.loc[idx,][\"Height\"]) <= threshold].index\n",
    "        idx3 = X.loc[idx,].loc[BMI(X.loc[idx,][\"Weight\"], X.loc[idx,][\"Height\"]) > threshold].index\n",
    "        \n",
    "        # set obesity from indexes above\n",
    "        X.loc[idx2,'Obesity'] = 0\n",
    "        X.loc[idx3,'Obesity'] = 1\n",
    "        return X\n",
    "    \n",
    "    def _fix_polydipsia(self, df, threshold=2.5):\n",
    "        idx = df[df['Polydipsia'].isna()].index\n",
    "        \n",
    "        # indexes to identify Urination above or below threshold\n",
    "        idx2 = df.loc[idx,].loc[df['Urination'] <= threshold].index\n",
    "        idx3 = df.loc[idx,].loc[df['Urination'] > threshold].index\n",
    "\n",
    "        # set Polydipsia from indexes above\n",
    "        df.loc[idx2,'Polydipsia'] = 0\n",
    "        df.loc[idx3,'Polydipsia'] = 1\n",
    "        #df.loc[idx,]\n",
    "        return df\n",
    "    \n",
    "    def set_output(self, *, transform: Literal['default', 'pandas'] | None = None) -> BaseEstimator:\n",
    "        return super().set_output(transform=transform)\n",
    "\n",
    "\n",
    "class AddBMI(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X['BMI'] = BMI(X['Weight'], X['Height'])\n",
    "        return X\n",
    "    def set_output(self, *, transform: Literal['default', 'pandas'] | None = None) -> BaseEstimator:\n",
    "        return super().set_output(transform=transform)\n",
    "\n",
    "class Outliers(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        bounds = self._outliers_z_score(X)\n",
    "\n",
    "        for f in bounds:\n",
    "            outliers = self._outliers_min_max(X, f,\n",
    "                                        min=bounds[0],\n",
    "                                        max=bounds[1]\n",
    "                                        )\n",
    "            X.loc[outliers.index, f] = np.NaN\n",
    "\n",
    "        assert type(X) == 'DataFrame'\n",
    "\n",
    "        return X\n",
    "    \n",
    "\n",
    "    def _outliers_z_score(df, feature, no_z=3):\n",
    "        lower = df[feature].mean()-no_z*df[feature].std()\n",
    "        upper = df[feature].mean()+no_z*df[feature].std()\n",
    "        return lower, upper\n",
    "    \n",
    "    def _outliers_min_max(df, feature, min=None, max=None):\n",
    "        try:\n",
    "            cond_min = df[feature] < min if min != None else False\n",
    "            cond_max = df[feature] > max if max != None else False\n",
    "            return df[cond_min | cond_max ]\n",
    "        except Exception as e:\n",
    "            print(\"invalid feature\")\n",
    "\n",
    "    def get_feature_names_out(self):\n",
    "        pass\n",
    "\n",
    "    def set_output(self, *, transform: Literal['default', 'pandas'] | None = None) -> BaseEstimator:\n",
    "        return super().set_output(transform=transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data\n",
    "\n",
    "I chose to read data directly for ease of testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "diabetes = pd.read_csv('diabetes.csv')\n",
    "binary_features = ['Obesity', 'TCep', 'Polydipsia', 'Sudden Weight Loss', 'Weakness',\n",
    "                'Polyphagia', 'Genital Thrush', 'Visual Blurring', 'Itching',\n",
    "                'Irritability', 'Delayed Healing', 'Partial Paresis', 'Muscle Stiffness', 'Alopecia', 'Gender']\n",
    "cat_features = ['Race',\t'Occupation',\t'GP']\n",
    "num_features = ['Age',\t'Height',\t'Weight',\t'Temperature',\t'Urination']\n",
    "\n",
    "\n",
    "target = 'Diabetes'\n",
    "y = diabetes[target]\n",
    "X = diabetes.drop(columns=target)\n",
    "# y = y.replace({'Positive':1, 'Negative':0}) # again, format on original data set\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_height(x, threshold=100):\n",
    "    \"\"\" Converts height in meters to centimeters, if height is less than threshold (default = 100)\"\"\"\n",
    "    col = x.columns[0]\n",
    "    mask = x[col] < threshold\n",
    "    x.loc[mask, [col]] = x.loc[mask, [col]].mul(100)\n",
    "    return x\n",
    "\n",
    "def fix_formating(x):\n",
    "    return x.replace({'yes':1, 'Yes': 1, 'Positive':1, 'no':0, 'No':0, 'Negative':0, 'Male':1,'Female':0})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing Pipeline\n",
    "\n",
    "I compose the pipeline from smaller pipelines, which all handles a subset of the tasks.\n",
    "\n",
    "The numeric, binary and categorical columns are all handled differently. \n",
    "In addition, construct a parametric preprocessor where we can impute with domain knowledge. We must adapt the functions from the other script to do so, and I have only done that to a few easy ones.\n",
    "\n",
    "For transformations which rely on other columns, like fixing obesity and polydipsia, we must use a slightly more complicated approach with classes, which I haven't attempted yet.\n",
    "\n",
    "Row wise transformations, like outliers, must also be implemented, and I have not looked at that either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/new/lib/python3.11/site-packages/sklearn/preprocessing/_function_transformer.py:345: UserWarning: With transform=\"pandas\", `func` should return a DataFrame to follow the set_output API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "This 'CustomTransformer' has no attribute 'set_output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb Cell 8\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#W6sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m preprocessor_general \u001b[39m=\u001b[39m ColumnTransformer(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#W6sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     transformers\u001b[39m=\u001b[39m[\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#W6sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m         (\u001b[39m\"\u001b[39m\u001b[39mnum\u001b[39m\u001b[39m\"\u001b[39m, num_transformer, num_features),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#W6sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     remainder\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdrop\u001b[39m\u001b[39m'\u001b[39m                \u001b[39m# drop untouched features since after this step, as it is the last preprocessing one\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#W6sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m )    \u001b[39m# Keep data frame format\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#W6sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m preprocessor \u001b[39m=\u001b[39m Pipeline(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#W6sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     steps\u001b[39m=\u001b[39m[\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#W6sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m         (\u001b[39m'\u001b[39m\u001b[39mCustom impute\u001b[39m\u001b[39m'\u001b[39m, CustomTransformer()),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#W6sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m         ]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#W6sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#W6sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m clf \u001b[39m=\u001b[39m Pipeline(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#W6sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     steps\u001b[39m=\u001b[39;49m[\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#W6sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m         (\u001b[39m'\u001b[39;49m\u001b[39mpreprocessor\u001b[39;49m\u001b[39m'\u001b[39;49m, preprocessor),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#W6sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m         (\u001b[39m\"\u001b[39;49m\u001b[39mclassifier\u001b[39;49m\u001b[39m\"\u001b[39;49m, tree\u001b[39m.\u001b[39;49mDecisionTreeClassifier())\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#W6sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m         ]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#W6sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m )\u001b[39m.\u001b[39;49mset_output(transform\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpandas\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#W6sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake_clf\u001b[39m(clf):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#W6sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m Pipeline(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#W6sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m     steps\u001b[39m=\u001b[39m[\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#W6sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m         (\u001b[39m'\u001b[39m\u001b[39mpreprocessor\u001b[39m\u001b[39m'\u001b[39m, preprocessor),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#W6sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m         (\u001b[39m\"\u001b[39m\u001b[39mclassifier\u001b[39m\u001b[39m\"\u001b[39m, clf)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#W6sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m         ]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#W6sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/new/lib/python3.11/site-packages/sklearn/pipeline.py:181\u001b[0m, in \u001b[0;36mPipeline.set_output\u001b[0;34m(self, transform)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Set the output container when `\"transform\"` and `\"fit_transform\"` are called.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \n\u001b[1;32m    164\u001b[0m \u001b[39mCalling `set_output` will set the output of all estimators in `steps`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39m    Estimator instance.\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[39mfor\u001b[39;00m _, _, step \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter():\n\u001b[0;32m--> 181\u001b[0m     _safe_set_output(step, transform\u001b[39m=\u001b[39;49mtransform)\n\u001b[1;32m    182\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/new/lib/python3.11/site-packages/sklearn/utils/_set_output.py:299\u001b[0m, in \u001b[0;36m_safe_set_output\u001b[0;34m(estimator, transform)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39mset_output\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    295\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    296\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnable to configure output for \u001b[39m\u001b[39m{\u001b[39;00mestimator\u001b[39m}\u001b[39;00m\u001b[39m because `set_output` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mis not available.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m     )\n\u001b[0;32m--> 299\u001b[0m \u001b[39mreturn\u001b[39;00m estimator\u001b[39m.\u001b[39;49mset_output(transform\u001b[39m=\u001b[39;49mtransform)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/new/lib/python3.11/site-packages/sklearn/pipeline.py:181\u001b[0m, in \u001b[0;36mPipeline.set_output\u001b[0;34m(self, transform)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Set the output container when `\"transform\"` and `\"fit_transform\"` are called.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \n\u001b[1;32m    164\u001b[0m \u001b[39mCalling `set_output` will set the output of all estimators in `steps`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39m    Estimator instance.\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[39mfor\u001b[39;00m _, _, step \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter():\n\u001b[0;32m--> 181\u001b[0m     _safe_set_output(step, transform\u001b[39m=\u001b[39;49mtransform)\n\u001b[1;32m    182\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/new/lib/python3.11/site-packages/sklearn/utils/_set_output.py:299\u001b[0m, in \u001b[0;36m_safe_set_output\u001b[0;34m(estimator, transform)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39mset_output\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    295\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    296\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnable to configure output for \u001b[39m\u001b[39m{\u001b[39;00mestimator\u001b[39m}\u001b[39;00m\u001b[39m because `set_output` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mis not available.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m     )\n\u001b[0;32m--> 299\u001b[0m \u001b[39mreturn\u001b[39;00m estimator\u001b[39m.\u001b[39;49mset_output(transform\u001b[39m=\u001b[39;49mtransform)\n",
      "\u001b[1;32m/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb Cell 8\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#W6sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_output\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m, transform: Literal[\u001b[39m'\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpandas\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BaseEstimator:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#W6sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mset_output(transform\u001b[39m=\u001b[39mtransform)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/new/lib/python3.11/site-packages/sklearn/utils/_available_if.py:32\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     \u001b[39m# delegate only on instances, not the classes.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[39m# this is to allow access to the docstrings.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck(obj):\n\u001b[0;32m---> 32\u001b[0m         \u001b[39mraise\u001b[39;00m attr_err\n\u001b[1;32m     33\u001b[0m     out \u001b[39m=\u001b[39m MethodType(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn, obj)\n\u001b[1;32m     35\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m     \u001b[39m# This makes it possible to use the decorated method as an unbound method,\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     \u001b[39m# for instance when monkeypatching.\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: This 'CustomTransformer' has no attribute 'set_output'"
     ]
    }
   ],
   "source": [
    "# Parametric preprocessor where we impute with domain knowledge\n",
    "preprocessor_parametric = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('fix height', FunctionTransformer(fix_height), ['Height']),\n",
    "    ],\n",
    "    verbose_feature_names_out= False, # Keeps the same column name for future processing\n",
    "    remainder='passthrough'         # Doesent drop untransformed columns\n",
    ").set_output(transform='pandas')    # Keep data frame format\n",
    "\n",
    "binary_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('Fix formating', FunctionTransformer(fix_formating)),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=0)),\n",
    "        # Differential privacy here\n",
    "        # (\"selector\", SelectKBest(k=3)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "cat_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"infrequent_if_exist\", min_frequency=0.1, sparse=False)),\n",
    "        # Unsure how to introduce privacy,\n",
    "        # (\"selector\", SelectKBest(k=3)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "num_transformer = Pipeline(\n",
    "    steps=[\n",
    "           # Differential privacy here\n",
    "           # Outliers Here\n",
    "            # ('Outliers', Outliers()), # BROKEN\n",
    "            (\"imputer\", SimpleImputer(strategy=\"mean\")), \n",
    "            (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "\n",
    "# General preprocesser which encodes and scales all features\n",
    "preprocessor_general = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_transformer, num_features),\n",
    "        (\"cat\", cat_transformer, cat_features),\n",
    "        ('binary', binary_transformer, binary_features)\n",
    "    ],\n",
    "    verbose_feature_names_out= True,\n",
    "    remainder='drop'                # drop untouched features since after this step, as it is the last preprocessing one\n",
    ").set_output(transform=\"pandas\")    # Keep data frame format\n",
    "\n",
    "\n",
    "preprocessor = Pipeline(\n",
    "    steps=[\n",
    "        ('Custom impute', CustomTransformer()),\n",
    "        # ('Add columns', AddBMI()),\n",
    "        (\"preprocessor parametric\", preprocessor_parametric), \n",
    "        (\"preprocessor general\", preprocessor_general), \n",
    "        ]\n",
    ")\n",
    "\n",
    "\n",
    "clf = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        (\"classifier\", tree.DecisionTreeClassifier())\n",
    "        ]\n",
    ")\n",
    "\n",
    "\n",
    "def make_clf(clf):\n",
    "    return Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        (\"classifier\", clf)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "clf # Displays the pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running pipeline\n",
    "## Predicting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Outliers' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y) \u001b[39m# Simple train-test spliot\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m clf\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTrain score: \u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m clf\u001b[39m.\u001b[39mscore(X_train, y_train))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTest score: \u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m clf\u001b[39m.\u001b[39mscore(X_test, y_test))\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/new/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/new/lib/python3.11/site-packages/sklearn/pipeline.py:423\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \n\u001b[1;32m    399\u001b[0m \u001b[39mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[39m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    422\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m--> 423\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps)\n\u001b[1;32m    424\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[1;32m    425\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/new/lib/python3.11/site-packages/sklearn/pipeline.py:377\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    375\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[1;32m    376\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 377\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[1;32m    378\u001b[0m     cloned_transformer,\n\u001b[1;32m    379\u001b[0m     X,\n\u001b[1;32m    380\u001b[0m     y,\n\u001b[1;32m    381\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    382\u001b[0m     message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPipeline\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    383\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(step_idx),\n\u001b[1;32m    384\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps[name],\n\u001b[1;32m    385\u001b[0m )\n\u001b[1;32m    386\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/new/lib/python3.11/site-packages/joblib/memory.py:353\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 353\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/new/lib/python3.11/site-packages/sklearn/pipeline.py:957\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    956\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 957\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit_transform(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    958\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    959\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/new/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/new/lib/python3.11/site-packages/sklearn/pipeline.py:479\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    477\u001b[0m fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(last_step, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 479\u001b[0m     \u001b[39mreturn\u001b[39;00m last_step\u001b[39m.\u001b[39;49mfit_transform(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[1;32m    480\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    481\u001b[0m     \u001b[39mreturn\u001b[39;00m last_step\u001b[39m.\u001b[39mfit(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\u001b[39m.\u001b[39mtransform(Xt)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/new/lib/python3.11/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/new/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/new/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:754\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_column_callables(X)\n\u001b[1;32m    752\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_remainder(X)\n\u001b[0;32m--> 754\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_transform(X, y, _fit_transform_one)\n\u001b[1;32m    756\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m result:\n\u001b[1;32m    757\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_fitted_transformers([])\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/new/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:681\u001b[0m, in \u001b[0;36mColumnTransformer._fit_transform\u001b[0;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[1;32m    675\u001b[0m transformers \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[1;32m    676\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(\n\u001b[1;32m    677\u001b[0m         fitted\u001b[39m=\u001b[39mfitted, replace_strings\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, column_as_strings\u001b[39m=\u001b[39mcolumn_as_strings\n\u001b[1;32m    678\u001b[0m     )\n\u001b[1;32m    679\u001b[0m )\n\u001b[1;32m    680\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 681\u001b[0m     \u001b[39mreturn\u001b[39;00m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[1;32m    682\u001b[0m         delayed(func)(\n\u001b[1;32m    683\u001b[0m             transformer\u001b[39m=\u001b[39;49mclone(trans) \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m fitted \u001b[39melse\u001b[39;49;00m trans,\n\u001b[1;32m    684\u001b[0m             X\u001b[39m=\u001b[39;49m_safe_indexing(X, column, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m),\n\u001b[1;32m    685\u001b[0m             y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    686\u001b[0m             weight\u001b[39m=\u001b[39;49mweight,\n\u001b[1;32m    687\u001b[0m             message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mColumnTransformer\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    688\u001b[0m             message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(name, idx, \u001b[39mlen\u001b[39;49m(transformers)),\n\u001b[1;32m    689\u001b[0m         )\n\u001b[1;32m    690\u001b[0m         \u001b[39mfor\u001b[39;49;00m idx, (name, trans, column, weight) \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(transformers, \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    691\u001b[0m     )\n\u001b[1;32m    692\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    693\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(e):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/new/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/new/lib/python3.11/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/new/lib/python3.11/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/new/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/new/lib/python3.11/site-packages/sklearn/pipeline.py:957\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    956\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 957\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit_transform(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    958\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    959\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/new/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/new/lib/python3.11/site-packages/sklearn/pipeline.py:471\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model and transform with the final estimator.\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \n\u001b[1;32m    446\u001b[0m \u001b[39mFits all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[39m    Transformed samples.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    470\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m--> 471\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps)\n\u001b[1;32m    473\u001b[0m last_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\n\u001b[1;32m    474\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/new/lib/python3.11/site-packages/sklearn/pipeline.py:377\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    375\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[1;32m    376\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 377\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[1;32m    378\u001b[0m     cloned_transformer,\n\u001b[1;32m    379\u001b[0m     X,\n\u001b[1;32m    380\u001b[0m     y,\n\u001b[1;32m    381\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    382\u001b[0m     message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPipeline\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    383\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(step_idx),\n\u001b[1;32m    384\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps[name],\n\u001b[1;32m    385\u001b[0m )\n\u001b[1;32m    386\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/new/lib/python3.11/site-packages/joblib/memory.py:353\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 353\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/new/lib/python3.11/site-packages/sklearn/pipeline.py:957\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    956\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 957\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit_transform(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    958\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    959\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/new/lib/python3.11/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/new/lib/python3.11/site-packages/sklearn/base.py:919\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    917\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    918\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m--> 919\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39;49mtransform(X)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/new/lib/python3.11/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "\u001b[1;32m/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb Cell 10\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#X12sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#X12sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     bounds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_outliers_z_score(X)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#X12sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m bounds:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#X12sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m         outliers \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outliers_min_max(X, f,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#X12sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m                                     \u001b[39mmin\u001b[39m\u001b[39m=\u001b[39mbounds[\u001b[39m0\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#X12sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m                                     \u001b[39mmax\u001b[39m\u001b[39m=\u001b[39mbounds[\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#X12sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m                                     )\n",
      "\u001b[1;32m/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb Cell 10\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#X12sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_outliers_z_score\u001b[39m(df, feature, no_z\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#X12sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     lower \u001b[39m=\u001b[39m df[feature]\u001b[39m.\u001b[39mmean()\u001b[39m-\u001b[39mno_z\u001b[39m*\u001b[39mdf[feature]\u001b[39m.\u001b[39mstd()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#X12sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m     upper \u001b[39m=\u001b[39m df[feature]\u001b[39m.\u001b[39mmean()\u001b[39m+\u001b[39mno_z\u001b[39m*\u001b[39mdf[feature]\u001b[39m.\u001b[39mstd()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/even/edu/in-stk5000/IN-STK5000-9000-Project-2/pipe.ipynb#X12sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m lower, upper\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Outliers' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y) # Simple train-test spliot\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Train score: %.3f\" % clf.score(X_train, y_train))\n",
    "print(\"Test score: %.3f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformed data frame\n",
    "\n",
    "Allows inspection into the final preprocessed data frame which the prediction model trains on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__Age</th>\n",
       "      <th>num__Height</th>\n",
       "      <th>num__Weight</th>\n",
       "      <th>num__Temperature</th>\n",
       "      <th>num__Urination</th>\n",
       "      <th>cat__Race_White</th>\n",
       "      <th>cat__Race_infrequent_sklearn</th>\n",
       "      <th>cat__Occupation_Manager</th>\n",
       "      <th>cat__Occupation_Retired</th>\n",
       "      <th>cat__Occupation_infrequent_sklearn</th>\n",
       "      <th>...</th>\n",
       "      <th>binary__Polyphagia</th>\n",
       "      <th>binary__Genital Thrush</th>\n",
       "      <th>binary__Visual Blurring</th>\n",
       "      <th>binary__Itching</th>\n",
       "      <th>binary__Irritability</th>\n",
       "      <th>binary__Delayed Healing</th>\n",
       "      <th>binary__Partial Paresis</th>\n",
       "      <th>binary__Muscle Stiffness</th>\n",
       "      <th>binary__Alopecia</th>\n",
       "      <th>binary__Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>-0.417575</td>\n",
       "      <td>-0.797727</td>\n",
       "      <td>-1.477687</td>\n",
       "      <td>0.666871</td>\n",
       "      <td>0.297890</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>-0.171111</td>\n",
       "      <td>0.965308</td>\n",
       "      <td>-0.413059</td>\n",
       "      <td>1.455879</td>\n",
       "      <td>-0.808163</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>-0.565454</td>\n",
       "      <td>-0.576390</td>\n",
       "      <td>-0.868226</td>\n",
       "      <td>-0.122137</td>\n",
       "      <td>-0.836524</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.814745</td>\n",
       "      <td>-0.043646</td>\n",
       "      <td>-0.581496</td>\n",
       "      <td>1.160001</td>\n",
       "      <td>0.562587</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>0.075353</td>\n",
       "      <td>-0.670290</td>\n",
       "      <td>-0.312125</td>\n",
       "      <td>-0.171450</td>\n",
       "      <td>-0.883791</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1.159795</td>\n",
       "      <td>1.125323</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>-0.171450</td>\n",
       "      <td>0.401878</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.294588</td>\n",
       "      <td>-0.042110</td>\n",
       "      <td>0.370993</td>\n",
       "      <td>-0.571827</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>0.075353</td>\n",
       "      <td>-2.549264</td>\n",
       "      <td>-0.746720</td>\n",
       "      <td>0.173741</td>\n",
       "      <td>0.751656</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>-0.516161</td>\n",
       "      <td>-1.148418</td>\n",
       "      <td>-0.857940</td>\n",
       "      <td>-0.270076</td>\n",
       "      <td>0.174995</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.269697</td>\n",
       "      <td>0.696062</td>\n",
       "      <td>1.116381</td>\n",
       "      <td>1.258627</td>\n",
       "      <td>-1.252476</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>409 rows  26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     num__Age  num__Height  num__Weight  num__Temperature  num__Urination  \\\n",
       "452 -0.417575    -0.797727    -1.477687          0.666871        0.297890   \n",
       "503 -0.171111     0.965308    -0.413059          1.455879       -0.808163   \n",
       "110 -0.565454    -0.576390    -0.868226         -0.122137       -0.836524   \n",
       "37   0.814745    -0.043646    -0.581496          1.160001        0.562587   \n",
       "402  0.075353    -0.670290    -0.312125         -0.171450       -0.883791   \n",
       "..        ...          ...          ...               ...             ...   \n",
       "130  1.159795     1.125323     0.005464         -0.171450        0.401878   \n",
       "254  0.000000     0.294588    -0.042110          0.370993       -0.571827   \n",
       "373  0.075353    -2.549264    -0.746720          0.173741        0.751656   \n",
       "64  -0.516161    -1.148418    -0.857940         -0.270076        0.174995   \n",
       "10  -0.269697     0.696062     1.116381          1.258627       -1.252476   \n",
       "\n",
       "     cat__Race_White  cat__Race_infrequent_sklearn  cat__Occupation_Manager  \\\n",
       "452              1.0                           0.0                      0.0   \n",
       "503              1.0                           0.0                      0.0   \n",
       "110              1.0                           0.0                      0.0   \n",
       "37               1.0                           0.0                      0.0   \n",
       "402              1.0                           0.0                      0.0   \n",
       "..               ...                           ...                      ...   \n",
       "130              1.0                           0.0                      0.0   \n",
       "254              1.0                           0.0                      0.0   \n",
       "373              1.0                           0.0                      0.0   \n",
       "64               1.0                           0.0                      1.0   \n",
       "10               1.0                           0.0                      1.0   \n",
       "\n",
       "     cat__Occupation_Retired  cat__Occupation_infrequent_sklearn  ...  \\\n",
       "452                      0.0                                 1.0  ...   \n",
       "503                      0.0                                 1.0  ...   \n",
       "110                      0.0                                 1.0  ...   \n",
       "37                       1.0                                 0.0  ...   \n",
       "402                      0.0                                 1.0  ...   \n",
       "..                       ...                                 ...  ...   \n",
       "130                      1.0                                 0.0  ...   \n",
       "254                      0.0                                 1.0  ...   \n",
       "373                      0.0                                 1.0  ...   \n",
       "64                       0.0                                 0.0  ...   \n",
       "10                       0.0                                 0.0  ...   \n",
       "\n",
       "     binary__Polyphagia  binary__Genital Thrush  binary__Visual Blurring  \\\n",
       "452                 0.0                     0.0                      1.0   \n",
       "503                 1.0                     1.0                      0.0   \n",
       "110                 0.0                     0.0                      0.0   \n",
       "37                  0.0                     0.0                      1.0   \n",
       "402                 0.0                     0.0                      1.0   \n",
       "..                  ...                     ...                      ...   \n",
       "130                 1.0                     0.0                      1.0   \n",
       "254                 0.0                     0.0                      0.0   \n",
       "373                 1.0                     0.0                      0.0   \n",
       "64                  1.0                     0.0                      1.0   \n",
       "10                  0.0                     1.0                      0.0   \n",
       "\n",
       "     binary__Itching  binary__Irritability  binary__Delayed Healing  \\\n",
       "452              1.0                   0.0                      0.0   \n",
       "503              0.0                   0.0                      0.0   \n",
       "110              0.0                   0.0                      1.0   \n",
       "37               1.0                   1.0                      1.0   \n",
       "402              0.0                   0.0                      1.0   \n",
       "..               ...                   ...                      ...   \n",
       "130              1.0                   0.0                      1.0   \n",
       "254              0.0                   0.0                      0.0   \n",
       "373              0.0                   0.0                      1.0   \n",
       "64               1.0                   1.0                      1.0   \n",
       "10               0.0                   0.0                      1.0   \n",
       "\n",
       "     binary__Partial Paresis  binary__Muscle Stiffness  binary__Alopecia  \\\n",
       "452                      1.0                       1.0               0.0   \n",
       "503                      0.0                       0.0               0.0   \n",
       "110                      0.0                       0.0               1.0   \n",
       "37                       1.0                       0.0               0.0   \n",
       "402                      0.0                       0.0               0.0   \n",
       "..                       ...                       ...               ...   \n",
       "130                      1.0                       1.0               1.0   \n",
       "254                      0.0                       0.0               0.0   \n",
       "373                      1.0                       0.0               0.0   \n",
       "64                       1.0                       1.0               0.0   \n",
       "10                       0.0                       0.0               1.0   \n",
       "\n",
       "     binary__Gender  \n",
       "452             0.0  \n",
       "503             1.0  \n",
       "110             1.0  \n",
       "37              0.0  \n",
       "402             0.0  \n",
       "..              ...  \n",
       "130             1.0  \n",
       "254             1.0  \n",
       "373             0.0  \n",
       "64              0.0  \n",
       "10              1.0  \n",
       "\n",
       "[409 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(preprocessor.fit_transform(X_train, y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "max depth: 1\n",
      "\tTrain score: 1.000\n",
      "\tTest score: 0.832\n",
      "\n",
      "max depth: 2\n",
      "\tTrain score: 1.000\n",
      "\tTest score: 0.832\n",
      "\n",
      "max depth: 3\n",
      "\tTrain score: 1.000\n",
      "\tTest score: 0.839\n",
      "\n",
      "max depth: 4\n",
      "\tTrain score: 1.000\n",
      "\tTest score: 0.839\n",
      "\n",
      "max depth: 5\n",
      "\tTrain score: 1.000\n",
      "\tTest score: 0.832\n",
      "\n",
      "max depth: 6\n",
      "\tTrain score: 1.000\n",
      "\tTest score: 0.825\n",
      "\n",
      "max depth: 7\n",
      "\tTrain score: 1.000\n",
      "\tTest score: 0.839\n",
      "\n",
      "max depth: 8\n",
      "\tTrain score: 1.000\n",
      "\tTest score: 0.847\n",
      "\n",
      "max depth: 9\n",
      "\tTrain score: 1.000\n",
      "\tTest score: 0.832\n",
      "\n",
      "max depth: 10\n",
      "\tTrain score: 1.000\n",
      "\tTest score: 0.832\n",
      "\n",
      "max depth: 11\n",
      "\tTrain score: 1.000\n",
      "\tTest score: 0.854\n",
      "\n",
      "max depth: 12\n",
      "\tTrain score: 1.000\n",
      "\tTest score: 0.839\n",
      "\n",
      "max depth: 13\n",
      "\tTrain score: 1.000\n",
      "\tTest score: 0.832\n",
      "\n",
      "max depth: 14\n",
      "\tTrain score: 1.000\n",
      "\tTest score: 0.832\n",
      "\n",
      "max depth: 15\n",
      "\tTrain score: 1.000\n",
      "\tTest score: 0.818\n",
      "\n",
      "max depth: 16\n",
      "\tTrain score: 1.000\n",
      "\tTest score: 0.832\n",
      "\n",
      "max depth: 17\n",
      "\tTrain score: 1.000\n",
      "\tTest score: 0.825\n",
      "\n",
      "max depth: 18\n",
      "\tTrain score: 1.000\n",
      "\tTest score: 0.847\n",
      "\n",
      "max depth: 19\n",
      "\tTrain score: 1.000\n",
      "\tTest score: 0.861\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for depth in range(1,20):\n",
    "    print('\\nmax depth:', depth)\n",
    "    clf = make_clf(tree.DecisionTreeClassifier(max_depth=None)).fit(X_train, y_train)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"\\tTrain score: %.3f\" % clf.score(X_train, y_train))\n",
    "    print(\"\\tTest score: %.3f\" % clf.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
